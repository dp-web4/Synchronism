"""
U(1) Lattice Gauge Theory - 3+1D Static Potential
Synchronism Session #27: Coulomb Potential Emergence in Realistic Dimensions

Implements compact U(1) gauge theory on 3+1D lattice to measure
the static quark-antiquark potential via Polyakov loop correlators.

This extends the 2+1D validation to realistic spacetime dimensions,
testing if Coulomb potential V(R) = -Î±/R emerges naturally from
Synchronism's intent dynamics without being assumed.

Theoretical Framework:
- Î¸_Î¼(x) gauge links â†” Ï†_Î¼(x) intent phase direction
- Plaquette circulation â†” Intent coherence tension
- Polyakov loops â†” Long-range intent alignment
- Emergent V(R) â†” Cost of phase mismatch

Author: CBP Autonomous Synchronism Research
Date: 2025-11-19
Session: #27
Context: Nova November 8 recommendation - potential energy derivation
"""

import numpy as np
import matplotlib.pyplot as plt
from scipy.optimize import curve_fit
import sys
import os

# Import stats utilities from lattice-gauge tools
sys.path.append('/mnt/c/exe/projects/ai-agents/private-context/tools/lattice-gauge')
from stats_utils import jackknife_function, fit_coulomb_potential


class U1Lattice3p1D:
    """
    Compact U(1) lattice gauge theory in 3+1 dimensions.

    Lattice:
        - (Lx, Ly, Lz) spatial dimensions
        - Nt temporal dimension
        - 4 links per site (directions: x, y, z, t)

    Action:
        S = -Î² Î£_plaquettes cos(Î¸_Î¼Î½)

    where Î¸_Î¼Î½ is the plaquette phase circulation.

    Synchronism Interpretation:
        - Î¸_Î¼(x): Intent phase direction on link Î¼ at site x
        - Plaquette: Local coherence measurement (circulation of intent)
        - Î²: Coherence coupling strength (higher Î² â†’ stronger coherence)
        - Polyakov loop: Persistent intent alignment across temporal extent
    """

    def __init__(self, Lx, Ly, Lz, Nt, beta):
        """
        Initialize 3+1D lattice.

        Parameters:
        -----------
        Lx, Ly, Lz : int
            Spatial lattice dimensions
        Nt : int
            Temporal lattice dimension
        beta : float
            Inverse coupling (Î² = 1/gÂ²)
            In Synchronism: coherence strength parameter
        """
        self.Lx = Lx
        self.Ly = Ly
        self.Lz = Lz
        self.Nt = Nt
        self.beta = beta

        # 4 link directions: x(0), y(1), z(2), t(3)
        self.n_dirs = 4
        self.shape = (Lx, Ly, Lz, Nt, self.n_dirs)

        # Initialize with random phases Î¸ âˆˆ [-Ï€, Ï€]
        # In Synchronism: random initial intent orientations
        self.theta = np.random.uniform(-np.pi, np.pi, self.shape)

        print(f"Initialized {Lx}Ã—{Ly}Ã—{Lz}Ã—{Nt} lattice")
        print(f"  Total sites: {Lx * Ly * Lz * Nt}")
        print(f"  Total links: {Lx * Ly * Lz * Nt * self.n_dirs}")
        print(f"  Î² = {beta}")

    def plaquette_phase(self, x, y, z, t, mu, nu):
        """
        Calculate plaquette phase circulation.

        Î¸_plaq = Î¸_Î¼(x) + Î¸_Î½(x+Î¼) - Î¸_Î¼(x+Î½) - Î¸_Î½(x)

        This is the Wilson loop around a unit square in the Î¼-Î½ plane.

        In Synchronism: measures local intent circulation (coherence).
        Perfect coherence â†’ Î¸_plaq = 0 (all phases aligned)
        Maximum disorder â†’ Î¸_plaq ~ random (no coherence)

        Parameters:
        -----------
        x, y, z, t : int
            Site coordinates
        mu, nu : int
            Direction indices (0=x, 1=y, 2=z, 3=t)

        Returns:
        --------
        phase : float
            Plaquette phase in [-Ï€, Ï€]
        """
        # Î¸_Î¼(x)
        th1 = self.theta[x, y, z, t, mu]

        # Î¸_Î½(x+Î¼)
        xp = (x + int(mu == 0)) % self.Lx
        yp = (y + int(mu == 1)) % self.Ly
        zp = (z + int(mu == 2)) % self.Lz
        tp = (t + int(mu == 3)) % self.Nt
        th2 = self.theta[xp, yp, zp, tp, nu]

        # Î¸_Î¼(x+Î½)
        xp = (x + int(nu == 0)) % self.Lx
        yp = (y + int(nu == 1)) % self.Ly
        zp = (z + int(nu == 2)) % self.Lz
        tp = (t + int(nu == 3)) % self.Nt
        th3 = self.theta[xp, yp, zp, tp, mu]

        # Î¸_Î½(x)
        th4 = self.theta[x, y, z, t, nu]

        # Phase difference (wrapped to [-Ï€, Ï€])
        phase = th1 + th2 - th3 - th4
        phase = np.arctan2(np.sin(phase), np.cos(phase))

        return phase

    def action(self):
        """
        Calculate total Wilson plaquette action.

        S = -Î² Î£ cos(Î¸_plaq)

        In Synchronism: total coherence energy
        Lower action â†’ higher coherence â†’ more aligned intent phases

        Returns:
        --------
        S : float
            Total action
        """
        S = 0.0

        # Sum over all plaquettes
        # In 3+1D: 6 plaquette orientations per site
        # (xy, xz, xt, yz, yt, zt)
        for x in range(self.Lx):
            for y in range(self.Ly):
                for z in range(self.Lz):
                    for t in range(self.Nt):
                        for mu in range(self.n_dirs):
                            for nu in range(mu + 1, self.n_dirs):
                                phase = self.plaquette_phase(x, y, z, t, mu, nu)
                                S -= self.beta * np.cos(phase)

        return S

    def metropolis_update(self, x, y, z, t, mu, delta=0.5):
        """
        Metropolis update for single link.

        Proposes: Î¸' = Î¸ + Î´Î¸ where Î´Î¸ âˆˆ U(-Î´, Î´)
        Accepts with probability: min(1, exp(-Î”S))

        In Synchronism: intent phase fluctuation attempt
        Acceptance depends on coherence cost (action change)

        Parameters:
        -----------
        x, y, z, t : int
            Site coordinates
        mu : int
            Link direction
        delta : float
            Proposal width

        Returns:
        --------
        accepted : bool
            Whether update was accepted
        """
        # Current phase
        theta_old = self.theta[x, y, z, t, mu]

        # Proposal
        theta_new = theta_old + np.random.uniform(-delta, delta)
        theta_new = np.arctan2(np.sin(theta_new), np.cos(theta_new))

        # Change in action (only depends on staples)
        dS = self.staple_action_diff(x, y, z, t, mu, theta_old, theta_new)

        # Accept/reject (Metropolis criterion)
        if dS < 0 or np.random.rand() < np.exp(-dS):
            self.theta[x, y, z, t, mu] = theta_new
            return True
        return False

    def staple_action_diff(self, x, y, z, t, mu, theta_old, theta_new):
        """
        Calculate change in action for single link update.

        Only plaquettes touching the link contribute.
        In 3+1D: 6 staples per link (2 per orthogonal direction)

        Parameters:
        -----------
        x, y, z, t : int
            Site coordinates
        mu : int
            Link direction
        theta_old, theta_new : float
            Old and new link phases

        Returns:
        --------
        dS : float
            Change in action
        """
        staple = 0.0

        # Sum over staples (other directions)
        for nu in range(self.n_dirs):
            if nu == mu:
                continue

            # Forward staple: x â†’ x+Î¼ â†’ x+Î¼+Î½ â†’ x+Î½ â†’ x
            xp = (x + int(mu == 0)) % self.Lx
            yp = (y + int(mu == 1)) % self.Ly
            zp = (z + int(mu == 2)) % self.Lz
            tp = (t + int(mu == 3)) % self.Nt
            th1 = self.theta[xp, yp, zp, tp, nu]

            xp2 = (x + int(nu == 0)) % self.Lx
            yp2 = (y + int(nu == 1)) % self.Ly
            zp2 = (z + int(nu == 2)) % self.Lz
            tp2 = (t + int(nu == 3)) % self.Nt
            th2 = self.theta[xp2, yp2, zp2, tp2, mu]

            th3 = self.theta[x, y, z, t, nu]

            staple += np.cos(th1 - th2 - th3)

            # Backward staple: x â†’ x+Î¼ â†’ x+Î¼-Î½ â†’ x-Î½ â†’ x
            xm = (x - int(nu == 0)) % self.Lx
            ym = (y - int(nu == 1)) % self.Ly
            zm = (z - int(nu == 2)) % self.Lz
            tm = (t - int(nu == 3)) % self.Nt

            th1 = self.theta[xm, ym, zm, tm, nu]

            xp = (x + int(mu == 0)) % self.Lx
            yp = (y + int(mu == 1)) % self.Ly
            zp = (z + int(mu == 2)) % self.Lz
            tp = (t + int(mu == 3)) % self.Nt
            th2 = self.theta[xp, yp, zp, tp, nu]

            xpm = (xp - int(nu == 0)) % self.Lx
            ypm = (yp - int(nu == 1)) % self.Ly
            zpm = (zp - int(nu == 2)) % self.Lz
            tpm = (tp - int(nu == 3)) % self.Nt
            th3 = self.theta[xpm, ypm, zpm, tpm, mu]

            staple += np.cos(-th1 + th2 + th3)

        # Action difference
        dS_old = -self.beta * staple * np.cos(theta_old)
        dS_new = -self.beta * staple * np.cos(theta_new)

        return dS_new - dS_old

    def sweep(self):
        """
        Full lattice sweep (update all links once).

        In Synchronism: one Monte Carlo time step of intent dynamics

        Returns:
        --------
        acceptance : float
            Acceptance rate
        """
        n_accept = 0
        n_total = 0

        for x in range(self.Lx):
            for y in range(self.Ly):
                for z in range(self.Lz):
                    for t in range(self.Nt):
                        for mu in range(self.n_dirs):
                            if self.metropolis_update(x, y, z, t, mu):
                                n_accept += 1
                            n_total += 1

        return n_accept / n_total

    def polyakov_loop(self):
        """
        Calculate Polyakov loop at each spatial site.

        P(x,y,z) = Î _t exp(i * Î¸_t(x,y,z,t))

        In Synchronism: temporal coherence of intent at spatial location
        |P| = 1 â†’ perfect temporal alignment
        |P| = 0 â†’ no temporal coherence

        Returns:
        --------
        P : ndarray(Lx, Ly, Lz), complex
            Polyakov loop field
        """
        P = np.ones((self.Lx, self.Ly, self.Lz), dtype=complex)

        for t in range(self.Nt):
            # t-direction is index 3
            P *= np.exp(1j * self.theta[:, :, :, t, 3])

        return P

    def polyakov_correlator(self):
        """
        Measure Polyakov loop correlator C(R).

        C(R) = âŸ¨P(0) P*(R)âŸ© averaged over positions and orientations

        In Synchronism: spatial coherence correlation function
        Measures how intent alignment persists with distance

        Relation to potential:
        V(R) = -(1/Nt) * log|C(R)|

        Returns:
        --------
        R : ndarray
            Separations
        C : ndarray
            Correlators (complex)
        """
        P = self.polyakov_loop()

        # Calculate all separations
        max_R = min(self.Lx, self.Ly, self.Lz) // 2
        R_values = []
        C_values = []

        for dx in range(max_R):
            for dy in range(max_R):
                for dz in range(max_R):
                    if dx == 0 and dy == 0 and dz == 0:
                        continue

                    R = np.sqrt(dx**2 + dy**2 + dz**2)
                    if R > max_R:
                        continue

                    # Correlator
                    P_shifted = np.roll(np.roll(np.roll(P, dx, axis=0), dy, axis=1), dz, axis=2)
                    C = np.mean(P * np.conj(P_shifted))

                    R_values.append(R)
                    C_values.append(C)

        # Bin by R (average over equivalent separations)
        R_unique = np.unique(np.round(R_values, 2))
        C_binned = []

        for R in R_unique:
            mask = np.abs(np.array(R_values) - R) < 0.1
            C_binned.append(np.mean(np.array(C_values)[mask]))

        return R_unique, np.array(C_binned)

    def average_plaquette(self):
        """
        Calculate average plaquette value.

        âŸ¨PâŸ© = âŸ¨cos(Î¸_plaq)âŸ©

        In Synchronism: average local coherence
        âŸ¨PâŸ© = 1 â†’ perfect coherence
        âŸ¨PâŸ© = 0 â†’ complete disorder

        Returns:
        --------
        plaq : float
            Average plaquette
        """
        total = 0.0
        count = 0

        for x in range(self.Lx):
            for y in range(self.Ly):
                for z in range(self.Lz):
                    for t in range(self.Nt):
                        for mu in range(self.n_dirs):
                            for nu in range(mu + 1, self.n_dirs):
                                phase = self.plaquette_phase(x, y, z, t, mu, nu)
                                total += np.cos(phase)
                                count += 1

        return total / count


def run_simulation_3p1d(Lx=16, Ly=16, Lz=16, Nt=8, beta=2.0,
                        n_therm=500, n_meas=1000, meas_interval=10):
    """
    Run full 3+1D simulation and extract V(R).

    This is the core validation: does Coulomb potential emerge
    naturally from intent dynamics without being assumed?

    Parameters:
    -----------
    Lx, Ly, Lz, Nt : int
        Lattice dimensions
    beta : float
        Inverse coupling (coherence strength in Synchronism)
    n_therm : int
        Thermalization sweeps
    n_meas : int
        Measurement sweeps
    meas_interval : int
        Sweeps between measurements

    Returns:
    --------
    results : dict
        Contains R, V, dV, raw correlators, and diagnostics
    """
    print("="*70)
    print("Synchronism Session #27: 3+1D Lattice Gauge Theory")
    print("Testing Coulomb Potential Emergence")
    print("="*70)
    print(f"\nLattice: {Lx}Ã—{Ly}Ã—{Lz}Ã—{Nt}")
    print(f"Î² = {beta} (coherence coupling)")
    print(f"Thermalization: {n_therm} sweeps")
    print(f"Measurements: {n_meas} sweeps (every {meas_interval})")
    print()

    # Initialize lattice
    lattice = U1Lattice3p1D(Lx, Ly, Lz, Nt, beta)

    # Thermalization
    print("\n" + "="*70)
    print("THERMALIZATION PHASE")
    print("="*70)

    for i in range(n_therm):
        acc = lattice.sweep()

        if i % 100 == 0:
            plaq = lattice.average_plaquette()
            print(f"Sweep {i:4d}/{n_therm}: acceptance={acc:.3f}, âŸ¨plaqâŸ©={plaq:.4f}")

    print(f"\nâœ“ Thermalization complete")

    # Measurements
    print("\n" + "="*70)
    print("MEASUREMENT PHASE")
    print("="*70)

    correlators = {}
    plaquettes = []

    for i in range(n_meas):
        # Decorrelate
        for _ in range(meas_interval):
            lattice.sweep()

        # Measure Polyakov correlator
        R, C = lattice.polyakov_correlator()

        for r, c in zip(R, C):
            if r not in correlators:
                correlators[r] = []
            correlators[r].append(c)

        # Measure plaquette (diagnostic)
        plaquettes.append(lattice.average_plaquette())

        if i % 100 == 0:
            print(f"Measurement {i:4d}/{n_meas}: âŸ¨plaqâŸ©={plaquettes[-1]:.4f}")

    print(f"\nâœ“ Measurements complete")
    print(f"  Average plaquette: {np.mean(plaquettes):.4f} Â± {np.std(plaquettes):.4f}")

    # Extract potential: V(R) = -(1/Nt) log|C(R)|
    print("\n" + "="*70)
    print("POTENTIAL EXTRACTION")
    print("="*70)

    results = {
        'R': [],
        'V': [],
        'dV': [],
        'C_mean': [],
        'C_err': [],
        'C_raw': {},
        'plaquettes': np.array(plaquettes),
        'lattice_params': {
            'Lx': Lx, 'Ly': Ly, 'Lz': Lz, 'Nt': Nt,
            'beta': beta,
            'n_therm': n_therm,
            'n_meas': n_meas
        }
    }

    for R in sorted(correlators.keys()):
        C_samples = np.array(correlators[R])

        # Jackknife analysis for V(R) = -(1/Nt) log|C(R)|
        def log_abs(C_arr):
            C_mean = np.mean(C_arr)
            if np.abs(C_mean) < 1e-10:
                return np.nan
            return -np.log(np.abs(C_mean)) / Nt

        V, dV = jackknife_function(C_samples, log_abs)

        # Also compute correlator statistics
        C_mean = np.mean(C_samples)
        C_err = np.std(C_samples) / np.sqrt(len(C_samples))

        results['R'].append(R)
        results['V'].append(V)
        results['dV'].append(dV)
        results['C_mean'].append(C_mean)
        results['C_err'].append(C_err)
        results['C_raw'][R] = C_samples

        print(f"R={R:.2f}: V={V:+.4f} Â± {dV:.4f}, |C|={np.abs(C_mean):.4e}")

    results['R'] = np.array(results['R'])
    results['V'] = np.array(results['V'])
    results['dV'] = np.array(results['dV'])
    results['C_mean'] = np.array(results['C_mean'])
    results['C_err'] = np.array(results['C_err'])

    return results


def analyze_and_plot(results, output_prefix='session27_3p1d'):
    """
    Analyze results and create diagnostic plots.

    Parameters:
    -----------
    results : dict
        Simulation results
    output_prefix : str
        Prefix for output files
    """
    print("\n" + "="*70)
    print("ANALYSIS: COULOMB POTENTIAL FIT")
    print("="*70)

    # Fit to V(R) = -Î±/R + const
    fit = fit_coulomb_potential(results['R'], results['V'], results['dV'])

    print(f"\nFitted potential:")
    print(f"  V(R) = -{fit['alpha']:.4f} Â± {fit['alpha_err']:.4f} / R")
    print(f"         + {fit['const']:.4f} Â± {fit['const_err']:.4f}")
    print(f"\nFit quality:")
    print(f"  Ï‡Â²/dof = {fit['chi2_dof']:.3f}")
    print(f"  RÂ² = {fit.get('r_squared', 'N/A')}")

    # Interpretation
    print("\n" + "="*70)
    print("SYNCHRONISM INTERPRETATION")
    print("="*70)

    if fit['chi2_dof'] < 2.0:
        print("âœ“ EXCELLENT FIT - Coulomb potential emerges naturally!")
        print("  Intent dynamics generate V âˆ 1/R without assumption")
    elif fit['chi2_dof'] < 3.0:
        print("âœ“ GOOD FIT - Coulomb behavior observed")
        print("  May need more statistics for precise measurement")
    else:
        print("âš  POOR FIT - Potential does not match Coulomb form")
        print("  Either need different Î² or more measurements")

    print(f"\nCoupling constant (lattice units): Î± = {fit['alpha']:.4f} Â± {fit['alpha_err']:.4f}")
    print(f"Constant term: Vâ‚€ = {fit['const']:.4f} Â± {fit['const_err']:.4f}")

    # Compare to 2+1D result
    print("\n" + "="*70)
    print("COMPARISON TO 2+1D VALIDATION")
    print("="*70)
    print("Previous 2+1D result (Session #6):")
    print("  V(R) = -0.117Â±0.095/R + 0.995Â±0.044")
    print("  Ï‡Â²/dof = 0.29")
    print(f"\nCurrent 3+1D result:")
    print(f"  V(R) = -{fit['alpha']:.3f}Â±{fit['alpha_err']:.3f}/R + {fit['const']:.3f}Â±{fit['const_err']:.3f}")
    print(f"  Ï‡Â²/dof = {fit['chi2_dof']:.2f}")

    # Create plots
    print("\n" + "="*70)
    print("GENERATING DIAGNOSTIC PLOTS")
    print("="*70)

    fig, axes = plt.subplots(2, 2, figsize=(14, 12))

    # Plot 1: V(R) with fit
    ax = axes[0, 0]
    R_fit = np.linspace(results['R'].min(), results['R'].max(), 100)
    V_fit = -fit['alpha'] / R_fit + fit['const']

    ax.errorbar(results['R'], results['V'], yerr=results['dV'],
                fmt='o', label='Measured V(R)', capsize=3)
    ax.plot(R_fit, V_fit, 'r-', label=f'Fit: V = -{fit["alpha"]:.3f}/R + {fit["const"]:.3f}')
    ax.set_xlabel('R (lattice units)', fontsize=12)
    ax.set_ylabel('V(R)', fontsize=12)
    ax.set_title(f'Static Potential (Ï‡Â²/dof = {fit["chi2_dof"]:.2f})', fontsize=13)
    ax.legend()
    ax.grid(True, alpha=0.3)

    # Plot 2: Residuals
    ax = axes[0, 1]
    V_fit_data = -fit['alpha'] / results['R'] + fit['const']
    residuals = results['V'] - V_fit_data

    ax.errorbar(results['R'], residuals, yerr=results['dV'],
                fmt='o', capsize=3)
    ax.axhline(0, color='r', linestyle='--', label='Perfect fit')
    ax.set_xlabel('R (lattice units)', fontsize=12)
    ax.set_ylabel('V - V_fit', fontsize=12)
    ax.set_title('Fit Residuals', fontsize=13)
    ax.legend()
    ax.grid(True, alpha=0.3)

    # Plot 3: Correlator |C(R)|
    ax = axes[1, 0]
    C_abs = np.abs(results['C_mean'])
    ax.semilogy(results['R'], C_abs, 'o-', label='|C(R)|')
    ax.set_xlabel('R (lattice units)', fontsize=12)
    ax.set_ylabel('|C(R)|', fontsize=12)
    ax.set_title('Polyakov Loop Correlator', fontsize=13)
    ax.legend()
    ax.grid(True, alpha=0.3)

    # Plot 4: Plaquette history
    ax = axes[1, 1]
    ax.plot(results['plaquettes'], alpha=0.7)
    ax.axhline(np.mean(results['plaquettes']), color='r', linestyle='--',
               label=f'Mean: {np.mean(results["plaquettes"]):.4f}')
    ax.set_xlabel('Measurement', fontsize=12)
    ax.set_ylabel('âŸ¨PlaquetteâŸ©', fontsize=12)
    ax.set_title('Coherence Monitor (âŸ¨cos(Î¸_plaq)âŸ©)', fontsize=13)
    ax.legend()
    ax.grid(True, alpha=0.3)

    plt.tight_layout()

    plot_file = f'/mnt/c/exe/projects/ai-agents/synchronism/simulations/{output_prefix}_analysis.png'
    plt.savefig(plot_file, dpi=150)
    print(f"âœ“ Saved plot: {plot_file}")

    return fit


def main():
    """
    Main execution: Run 3+1D lattice gauge simulation.

    Session #27 Goal: Validate that Coulomb potential V âˆ 1/R
    emerges naturally from Synchronism's intent dynamics in realistic
    3+1 dimensional spacetime.
    """

    # Simulation parameters
    # Quick validation run (~5-10 min on standard CPU)
    params = {
        'Lx': 10,           # Spatial extent
        'Ly': 10,
        'Lz': 10,
        'Nt': 6,            # Temporal extent
        'beta': 2.0,        # Coherence coupling
        'n_therm': 200,     # Thermalization sweeps
        'n_meas': 500,      # Measurement sweeps
        'meas_interval': 5  # Decorrelation interval
    }

    print("\n" + "="*70)
    print("SESSION #27: LATTICE GAUGE THEORY - 3+1D EXTENSION")
    print("="*70)
    print("\nResearch Question:")
    print("  Does Coulomb potential V âˆ 1/R emerge naturally from")
    print("  Synchronism's intent dynamics in 3+1D spacetime?")
    print("\nContext:")
    print("  Nova's November 8 review identified that V âˆ 1/r was")
    print("  ASSUMED (not DERIVED) in Synchronism theory.")
    print("\nApproach:")
    print("  U(1) lattice gauge simulation where:")
    print("    - Phase field Î¸_Î¼(x) â†” Intent direction")
    print("    - Plaquette circulation â†” Coherence tension")
    print("    - Polyakov correlators â†” Long-range alignment")
    print("    - Emergent V(R) â†” Test if 1/R arises")
    print("\n" + "="*70)

    # Run simulation
    results = run_simulation_3p1d(**params)

    # Analyze and plot
    fit = analyze_and_plot(results)

    # Save results
    output_file = '/mnt/c/exe/projects/ai-agents/synchronism/simulations/session27_3p1d_results.npz'
    np.savez(output_file,
             R=results['R'],
             V=results['V'],
             dV=results['dV'],
             C_mean=results['C_mean'],
             C_err=results['C_err'],
             plaquettes=results['plaquettes'],
             fit_alpha=fit['alpha'],
             fit_alpha_err=fit['alpha_err'],
             fit_const=fit['const'],
             fit_const_err=fit['const_err'],
             fit_chi2_dof=fit['chi2_dof'],
             **results['lattice_params'])

    print(f"\nâœ“ Saved results: {output_file}")

    # Final summary
    print("\n" + "="*70)
    print("SESSION #27 SUMMARY")
    print("="*70)
    print(f"\nâœ“ 3+1D lattice gauge simulation complete")
    print(f"âœ“ Coulomb potential fit: V(R) = -{fit['alpha']:.3f}/R + {fit['const']:.3f}")
    print(f"âœ“ Fit quality: Ï‡Â²/dof = {fit['chi2_dof']:.2f}")

    if fit['chi2_dof'] < 2.0:
        print(f"\nðŸŽ¯ SUCCESS: Coulomb potential EMERGES from intent dynamics!")
        print(f"   V âˆ 1/R is DERIVED, not ASSUMED")
        print(f"   Nova's critical gap ADDRESSED âœ“")
    else:
        print(f"\nâš  Need improvement: Consider adjusting Î² or increasing statistics")

    print("\n" + "="*70)
    print("Next Steps:")
    print("  1. Coupling calibration: Î² â†’ Î± = 1/137 (fine-structure)")
    print("  2. MRH screening test: V(R) â†’ V(R) Ã— exp(-R/Î»)")
    print("  3. Non-Abelian extension: SU(2), SU(3) gauge groups")
    print("="*70)
    print("\nDone!")


if __name__ == '__main__':
    main()
